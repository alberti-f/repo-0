{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e500b2ad-1f01-41ee-9036-d40239848b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fralberti/.local/lib/python3.8/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import mvlearn\n",
    "from mvlearn import embed\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import subprocess as sp\n",
    "import glob\n",
    "import hcp_utils as hcp\n",
    "\n",
    "\n",
    "### Smooth time series using wb_command\n",
    "def smooth_dtseries(in_dtseries, out_dtseries, kernel, L_surface, R_surface):\n",
    "    sp.run(f'wb_command -cifti-smoothing {in_dtseries} {kernel} {kernel} \\\n",
    "    COLUMN {out_dtseries} -left-surface {L_surface} -right-surface {R_surface} ',shell=True)\n",
    "    \n",
    "\n",
    "### Load the time series of the L and R hemisphere \n",
    "def load_dtseries(dtseries_path):\n",
    "    # load the file\n",
    "    dtseries = nib.load(dtseries_path)\n",
    "    # find the offset and number of vertices for each hemisphere\n",
    "    L_model = [x for x in dtseries.header.get_index_map(1).brain_models if x.brain_structure=='CIFTI_STRUCTURE_CORTEX_LEFT']\n",
    "    R_model = [x for x in dtseries.header.get_index_map(1).brain_models if x.brain_structure=='CIFTI_STRUCTURE_CORTEX_RIGHT']\n",
    "    offset_count = [L_model[0].index_offset, L_model[0].index_count,\n",
    "                    R_model[0].index_offset, R_model[0].index_count]\n",
    "    # extract the cortical timeseries\n",
    "    values = dtseries.get_fdata()\n",
    "    values = values[0:,np.append(np.arange(offset_count[0],offset_count[0]+offset_count[1]),np.arange(offset_count[2],offset_count[2]+offset_count[3]))]\n",
    "    \n",
    "    return values\n",
    "\n",
    "\n",
    "### Z-score and conatenation of dtseries of all subject folders in a directory\n",
    "def concat_dtseries(paths_to_dtseries):\n",
    "    if len(paths_to_dtseries)<2:\n",
    "        print(f'At least 2 time series are needed: {len(paths_to_dtseries)} found')\n",
    "    dtseries_lst = [load_dtseries(path) for path in paths_to_dtseries]\n",
    "    dtseries_lst = [hcp.normalize(dtseries) for dtseries in dtseries_lst]\n",
    "        \n",
    "    return np.concatenate(dtseries_lst)\n",
    "\n",
    "\n",
    "### Store gradients in cifti2 dscalar.nii\n",
    "def mk_grad1_dscalar(subject_ID, grads, template_cifti, output_dir):\n",
    "    # subject_ID: string array e.g. \"100206\"\n",
    "    # grads: array with dimensions gradients X vertices\n",
    "    # template_cifti: any cifti2 file with a BrainModelAxis (I am using one of the dtseries.nii)\n",
    "    # output_dir: path to output directory\n",
    "    data = np.zeros([grads.shape[0],template_cifti.shape[1]])\n",
    "    data[0:,0:grads.shape[1]] = grads\n",
    "\n",
    "    map_labels = [f'Gradient {i+1}' for i in range(grads.shape[0])]\n",
    "    ax0 = nib.cifti2.cifti2_axes.ScalarAxis(map_labels)\n",
    "    ax1 = nib.cifti2.cifti2_axes.from_index_mapping(template_cifti.header.get_index_map(1))\n",
    "    nifti_hdr = template_cifti.nifti_header\n",
    "    del template_cifti\n",
    "    \n",
    "    new_img = nib.Cifti2Image(data, header=[ax0, ax1],nifti_header=nifti_hdr)\n",
    "    new_img.update_headers()\n",
    "\n",
    "    new_img.to_filename(f\"{output_dir}{subject_ID}_gcca.dscalar.nii\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ae439a-95af-43b1-b1f6-05e61c40b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VARIABLES TO SET BEFORE RUNNING\n",
    "# directory containing subdirectories named fter subject IDs that contain the timeseries and surface files\n",
    "root_dir = \"/home/fralberti/Data/HCP_func/\"\n",
    "# directory where all intermediate files and the final output will be saved\n",
    "output_dir = \"/home/fralberti/Data/HCP_func/Pctile_output/\"\n",
    "# list of IDs of subjects to include in the analyses\n",
    "subj_id = [\"101006\",\"100610\",\"100408\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd9a8b26-daea-46c6-8ba2-f30b01366004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing time series\n",
      "Current subject:\n",
      "\t101006\n",
      "\t100610\n",
      "\t100408\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Smooth time series\n",
    "print('Smoothing time series\\nCurrent subject:')\n",
    "for subj in subj_id:\n",
    "    dtseries_dirs = ['rfMRI_REST1_LR','rfMRI_REST1_RL']\n",
    "    print(f'\\t{subj}')\n",
    "    for dir_tmp in dtseries_dirs:\n",
    "        kernel = 6\n",
    "        in_dtseries = f'{root_dir}{subj}/MNINonLinear/Results/{dir_tmp}/*_MSMAll.dtseries.nii'\n",
    "        out_dtseries = f'{root_dir}{subj}/MNINonLinear/Results/{dir_tmp}/{dir_tmp}_Atlas_MSMAll_smooth{kernel}.dtseries.nii'\n",
    "        ### the surfaces should be reachable from the root!\n",
    "        L_surface = f'/home/fralberti/Data/HCP_zone_prim/{subj}/{subj}.L.midthickness_MSMAll.32k_fs_LR.surf.gii'\n",
    "        R_surface = f'/home/fralberti/Data/HCP_zone_prim/{subj}/{subj}.R.midthickness_MSMAll.32k_fs_LR.surf.gii'\n",
    "        \n",
    "        smooth_dtseries(in_dtseries, out_dtseries, kernel, L_surface, R_surface)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe58dfe-5191-4700-9b73-433d87e07320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating smoothed time series\n",
      "Current subject:\n",
      "\t101006\n",
      "\t100610\n",
      "\t100408\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Normalize and conatenate time series\n",
    "print('Concatenating smoothed time series\\nCurrent subject:')\n",
    "for subj in subj_id:\n",
    "    print(f'\\t{subj}')\n",
    "    paths_to_dtseries = glob.glob(f'{root_dir}{subj}/MNINonLinear/Results/*/*_smooth6.dtseries.nii')\n",
    "    dtseries_out = concat_dtseries(paths_to_dtseries)\n",
    "    np.save(f'{output_dir}/{subj}_rfMRI_REST_concat.npy',dtseries_out)\n",
    "    del dtseries_out\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f135f45-ea37-4aea-b8e7-143a0b8315d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GCCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving output to cifti2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Compute GCCA\n",
    "dtseries_lst = [np.array(np.load(f'{output_dir}{subj}_rfMRI_REST_concat.npy')).T for subj in subj_id]\n",
    "\n",
    "print(\"Running GCCA\")\n",
    "gcca = embed.GCCA(n_components=4)\n",
    "res = gcca.fit_transform(dtseries_lst)\n",
    "del dtseries_lst\n",
    "\n",
    "print(\"Saving output to cifti2\")\n",
    "for i,subj in enumerate(subj_id):\n",
    "    grads = res[i,:,:].T\n",
    "    template_cifti = nib.load(f'{root_dir}HCP_S1200_GroupAvg_v1/S1200.All.midthickness_MSMAll_va.32k_fs_LR.dscalar.nii')\n",
    "    mk_grad1_dscalar(subj, grads, template_cifti, output_dir)\n",
    "del res\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
