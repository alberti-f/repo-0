{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf0612-9612-442b-9b5a-df79faec6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mvlearn.embed import GCCA # To install: \n",
    "%matplotlib inline\n",
    "import nilearn.plotting as plotting\n",
    "import subprocess as sp\n",
    "import hcp_utils as hcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428dc68-9e35-4435-8a7a-71ae5b2e1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjList = ['101006','100610','100408']#open(\"goodSubjlist.txt\", \"r\")\n",
    "subjs = subjList#.read().split('\\n')\n",
    "#### set number of jobs as variable. doubles as number of input subjects to do at once \n",
    "subjs=subjs[0:3]\n",
    "print(len(subjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962abd8c-d9e6-4c27-981a-513c2f2af970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### save gifti file out. we'll output to intermediate gifti before using wb_command to convert to cifti \n",
    "def save_gifti(data,out):\n",
    "    gi = nib.gifti.GiftiImage()\n",
    "    da = nib.gifti.GiftiDataArray(np.float32(data), intent=0)\n",
    "    gi.add_gifti_data_array(da)\n",
    "    nib.save(gi,f'{out}.func.gii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef573358-7050-4829-9f7a-aab24bfe5a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### do the spatial smoothing of your cifti files\n",
    "#### edit these paths to fit the server structure. \n",
    "#### should just be minor edits of outer directories\n",
    "def smooth_ciftis(subj,kernel):\n",
    "        Lstr=glob.glob(f'/home/fralberti/Data/HCP_zone_prim/{subj}/{subj}.L.midthickness_MSMAll.32k_fs_LR.surf.gii')\n",
    "        Rstr=glob.glob(f'/home/fralberti/Data/HCP_zone_prim/{subj}/{subj}.R.midthickness_MSMAll.32k_fs_LR.surf.gii')\n",
    "        func=glob.glob(f'/home/fralberti/Data/HCP_func/{subj}/MNINonLinear/Results/*/*_MSMAll.dtseries.nii')\n",
    "\n",
    "        for j in func:\n",
    "            out=j.split('.dtseries.nii')[0]+'_smooth.dtseries.nii'\n",
    "            #### for runing on the server generate list of commands and then batch jobs to do all at once\n",
    "            sp.run(f'wb_command -cifti-smoothing {j} {kernel} {kernel} COLUMN {out} -left-surface {Lstr[0]} -right-surface {Rstr[0]} ',shell=True)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2f1b6-6105-416f-8ed3-757c96d5bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### in a server pipeline we should send these out as individual jobs\n",
    "for i in subjs:\n",
    "    print(i)\n",
    "    smooth_ciftis(i,6.0) # |pipe it to run on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11130f52-f6b6-46d9-88ea-137fe7fbbb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullTs(funcs):\n",
    "    ### function takes a list of functional runs corresponding to a given subject \n",
    "    Ldat=[]\n",
    "    Rdat=[]\n",
    "    for cifti in funcs:\n",
    "#         print(cifti)\n",
    "        img=nib.load(cifti).get_fdata()\n",
    "        img=hcp.normalize(img)\n",
    "        Ldat.append(img[:, hcp.struct.cortex_left].T)\n",
    "        Rdat.append(img[:, hcp.struct.cortex_right].T)\n",
    "    Lcort=np.hstack(Ldat)\n",
    "    Loffset=len(Lcort)\n",
    "    Rcort=np.hstack(Rdat)\n",
    "    \n",
    "    cortTs=np.vstack([Lcort,Rcort])\n",
    "    \n",
    "    return cortTs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c5eb6-2bd9-44b9-8a13-c82d9ec75854",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### can set up to load batches of subjects and launch in parallel\n",
    "\n",
    "subjs=dict.fromkeys(subjs)\n",
    "\n",
    "# cortTsGroup=[]\n",
    "#### set up multiple subjects time courses for the gcaa\n",
    "for subj in subjs.keys():\n",
    "    print(subj)\n",
    "    func=glob.glob(f'/home/fralberti/Data/HCP_func/{subj}/MNINonLinear/Results/*/*_smooth.dtseries.nii') \n",
    "    ### can be sent to cluster as multiple jobs\n",
    "    ### however job results must be loaded into a single list for the GCAA \n",
    "    ### save intermediates? or create dictionary to fill as diff\n",
    "    subjs[subj]=fullTs(func)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f737b8-1920-40f8-b26d-dacfcc5619df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gcaa(data,comps):\n",
    "    gcca = GCCA(n_components=comps)\n",
    "    if len(data)==1:\n",
    "        raise ValueError('a list of 2 or more subjects is required to run GCAA')\n",
    "    else:\n",
    "        print('running gcaa')\n",
    "        gcca.fit(data)\n",
    "        return gcca.transform(data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82bdee-7439-4018-9607-0c0d117c8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad_list=[]\n",
    "# for i,subj in enumerate(subjs.keys()):\n",
    "#     print(subj)\n",
    "#     sgrad_list = grad_list.append(subjs[subj][0:,0:1200])\n",
    "out=run_gcaa(grad_list,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacfc59f-8177-4729-970b-efcf7add54c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### save the gradients of each subject in it's associated dictionary and get ready to save as giftis. \n",
    "for i in range(out.shape[0]):\n",
    "    sub=list(subjs.keys())[i]\n",
    "    print(sub)\n",
    "    grads=[]\n",
    "    for j in range(out.shape[2]):\n",
    "        grads.append(hcp.cortex_data(out[i,:,j]))\n",
    "    subjs[sub]=np.vstack(grads).T\n",
    "#     subjs[list(subjs.keys())[i]]=hcp.cortex_data(out[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561663f-ec41-4a35-912f-b5759d6f83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save gradients as scalar\n",
    "\n",
    "offset=int(64984/2)\n",
    "for i in subjs.keys():  \n",
    "    outdir=f'Rest/{i}/MNINonLinear/Results/'\n",
    "    Lgifti=f'{outdir}/L.gradGCCA'\n",
    "    Rgifti=f'{outdir}/R.gradGCCA'\n",
    "    print(outdir)\n",
    "    \n",
    "    save_gifti(subjs[i][0:offset],Lgifti)\n",
    "    save_gifti(subjs[i][offset:],Rgifti)\n",
    "    \n",
    "    sp.run(f'wb_command -cifti-create-dense-scalar {outdir}/gradsGCCA.dscalar.nii -left-metric {Lgifti}.func.gii -right-metric {Rgifti}.func.gii',shell=True)\n",
    "    \n",
    "    os.remove(f'{Lgifti}.func.gii')\n",
    "    os.remove(f'{Rgifti}.func.gii')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a3c15f-33b7-464a-9fd7-4b1ab5396302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### here is where we want to output each dictionary entry into a cifti\n",
    "def mk_grad1_dscalar(subject_ID, grads, template_cifti, output_dir):\n",
    "    # subject_ID: string array e.g. \"100206\"\n",
    "    # grads: array with dimensions gradients X vertices\n",
    "    # template_cifti: any cifti2 file with a BrainModelAxis (I am using one of the dtseries.nii)\n",
    "    # output_dir: path to output directory\n",
    "\n",
    "    data = np.zeros([grads.shape[0],template_cifti.shape[1]])\n",
    "\n",
    "    data[0:,0:grads.shape[1]] = grads\n",
    "    \n",
    "    map_labels = [f'Gradient{i}' for i in range(grads.shape[0])]\n",
    "    ax0 = nib.cifti2.cifti2_axes.ScalarAxis(map_labels)\n",
    "    ax1 = template_cifti.header.get_axis(1)\n",
    "    new_img = nib.Cifti2Image(data, header=[ax0, ax1],nifti_header=template_cifti.nifti_header)\n",
    "    new_img.update_headers()\n",
    "\n",
    "    new_img.to_filename(\"%s%s_grad.dscalar.nii\" % (output_dir,subject_ID))\n",
    "    del template_cifti\n",
    "##### francescos implementation. which although better I can't get to work. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
