{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052a84f-2bff-4c13-a187-35141db1df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import surfdist as sd\n",
    "from surfdist import viz, load, utils, analysis\n",
    "import hcp_utils as hcp\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from nilearn.plotting import plot_surf_stat_map\n",
    "from itertools import combinations\n",
    "\n",
    "### Store gradients in cifti2 dscalar.nii\n",
    "### Store gradients in cifti2 dscalar.nii\n",
    "def mk_grad1_dscalar(grads, template_cifti, output_dir):\n",
    "    # grads: array with dimensions gradients X vertices\n",
    "    # template_cifti: any cifti2 file with a BrainModelAxis (I am using one of the dtseries.nii)\n",
    "    # output_dir: path to output directory\n",
    "    data = np.zeros([grads.shape[0],template_cifti.shape[1]])\n",
    "    data[0:,0:grads.shape[1]] = grads\n",
    "\n",
    "    map_labels = [f'Measure {i+1}' for i in range(grads.shape[0])]\n",
    "    ax0 = nib.cifti2.cifti2_axes.ScalarAxis(map_labels)\n",
    "    ax1 = nib.cifti2.cifti2_axes.from_index_mapping(template_cifti.header.get_index_map(1))\n",
    "    nifti_hdr = template_cifti.nifti_header\n",
    "    del template_cifti\n",
    "    \n",
    "    new_img = nib.Cifti2Image(data, header=[ax0, ax1],nifti_header=nifti_hdr)\n",
    "    new_img.update_headers()\n",
    "\n",
    "    new_img.to_filename(output_dir)\n",
    "\n",
    "def get_parcel(label,path_to_dlabel,brain_structure):\n",
    "    ### Get the vertex index of nodes included in a specified parcel\n",
    "    # label: label of the parcel of which you need the nodes\n",
    "    # path_to_dlabel: path to a cifti2.dlabel.nii file\n",
    "    # brain_structure: cifti2 brain structure\n",
    "    \n",
    "    cifti = nib.load(path_to_dlabel)\n",
    "    brain_model = [x for x in cifti.header.get_index_map(1).brain_models if x.brain_structure==brain_structure][0]\n",
    "    offset = brain_model.index_offset\n",
    "    count = brain_model.index_count\n",
    "    vertices = np.array(brain_model.vertex_indices[0:])\n",
    "\n",
    "    label_map = cifti.get_fdata().squeeze()[offset:offset+count]\n",
    "\n",
    "    label_lst = pd.DataFrame(cifti.header.get_axis(0).get_element(0)[1].values(),columns=('lab','col')).reset_index()\n",
    "    label_tmp = label_lst[label_lst['lab'].isin(label)]['index'].values\n",
    "    \n",
    "    del cifti\n",
    "    return [lab in label_tmp for lab in label_map], vertices[[lab in label_tmp for lab in label_map]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4d800-7ae8-4511-9733-9b8dc6128459",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VARIABLES TO SET BEFORE RUNNING\n",
    "# directory containing subdirectories named fter subject IDs that contain the timeseries and surface files\n",
    "root_dir = \"/home/fralberti/Data/HCP/\"\n",
    "# directory where all intermediate files and the final output will be saved\n",
    "output_dir = \"/home/fralberti/Data/Gradientile/\"\n",
    "# list of IDs of subjects to include in the analyses\n",
    "subj_id = np.array([\"100206\",\"100307\",\"100408\",\"100610\",\"101006\",\n",
    "                    \"101107\",\"101309\",\"101410\",\"101915\"])\n",
    "#                     ,\"102008\",\"102109\",\"102311\",\"102513\",\"102614\",\"102715\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc3b85-4200-4071-9804-967f23b2487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find the transmodal peak of the principal gradient in the lateral parietal area\n",
    "\n",
    "peaks = pd.DataFrame(columns=['ID','L_vtx','R_vtx','L_grad','R_grad'])\n",
    "\n",
    "for i,subj in enumerate(subj_id):\n",
    "    roi = []\n",
    "    grad = nib.load(f'{output_dir}{subj}.REST1_gcca.dscalar.nii')\n",
    "    for hemi in ['L','R']:\n",
    "        # define a mask to limit peak search to the lateral parietal and occipital cortex\n",
    "        label = [f'{hemi}_postcentral',f'{hemi}_supramarginal',f'{hemi}_inferiorparietal',f'{hemi}_superiorparietal',f'{hemi}_lateraloccipital']\n",
    "        path_to_dlabel = f'{root_dir}{subj}/MNINonLinear/fsaverage_LR32k/{subj}.aparc.32k_fs_LR.dlabel.nii'\n",
    "        brain_structure = ['CIFTI_STRUCTURE_CORTEX_LEFT' if hemi=='L' else 'CIFTI_STRUCTURE_CORTEX_RIGHT'][0]\n",
    "        mask, vtx = get_parcel(label,path_to_dlabel,brain_structure)\n",
    "        roi.extend(mask)\n",
    "        # find vertex with the highest gradient value (all gradients must follow the uni-to-transmodal direction)\n",
    "        bm = [x for x in grad.header.get_index_map(1).brain_models if x.brain_structure==brain_structure][0]\n",
    "        grad_hemi = grad.get_fdata()[0,bm.index_offset:bm.index_offset+bm.index_count][mask]\n",
    "        vertices = np.array(bm.vertex_indices)[mask]\n",
    "        peak_tmp = vertices[np.where(grad_hemi==grad_hemi.max())[0][0]]\n",
    "        peaks.loc[i,['ID',hemi+'_vtx',hemi+'_grad']] = [subj,peak_tmp,grad_hemi.max()]\n",
    "#     mk_grad1_dscalar(np.array(roi,ndmin=2), grad, f'/home/fralberti/Data/Gradientile/{subj}.peak_mask.dscalar.nii')\n",
    "peaks.to_csv(f'{output_dir}gradient1_peaks.csv',index=False)\n",
    "\n",
    "del grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de703649-1d58-4a95-831d-c810265667f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_peaks = pd.read_csv(f'{output_dir}gradient1_peaks.csv')\n",
    "gradientiles = pd.read_csv(f'{output_dir}grad1entiles.csv')\n",
    "int_vtx = gradientiles[(gradientiles.ID_vtx==gradientiles.ID_grad)][['ID_vtx','hemisphere','vertex1','vertex2','vertex3']]\n",
    "del gradientiles\n",
    "\n",
    "peak_dist_df = pd.DataFrame(columns=['ID_peak','ID_int','hemisphere','distance'])\n",
    "for subj_peak in subj_id:\n",
    "    for hemi in ['L','R']:\n",
    "        surf = nib.load(f'{root_dir}{subj_peak}/T1w/fsaverage_LR32k/{subj_peak}.{hemi}.midthickness_MSMAll.32k_fs_LR.surf.gii').darrays\n",
    "        coord = [surf[0].data,surf[1].data]\n",
    "        nodes = np.unique(surf[1].data)\n",
    "        for subj_int in subj_id:\n",
    "            src_vtx = int_vtx[(int_vtx.ID_vtx==int(subj_int)) & (int_vtx.hemisphere==hemi)][['vertex1','vertex2','vertex3']]\n",
    "            peak_tmp = grad_peaks.loc[grad_peaks.ID==int(subj_peak),f'{hemi}_vtx']\n",
    "            dist_tmp = sd.analysis.dist_calc(coord, nodes, src_vtx)\n",
    "            peak_dist_df = peak_dist_df.append({'ID_peak':subj_peak,'ID_int':subj_int,'hemisphere':hemi,\n",
    "                                                'distance':dist_tmp[peak_tmp][0]}, ignore_index=True)\n",
    "            del dist_tmp\n",
    "        del surf, coord, nodes\n",
    "        \n",
    "peak_dist_df.sort_values(['ID_peak','ID_int'],'Axis'==1).to_csv(f'{output_dir}peak_dist.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
