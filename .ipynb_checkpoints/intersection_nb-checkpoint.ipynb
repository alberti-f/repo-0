{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6218f67d-8e85-4ac8-b80e-909f64791842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fralberti/.local/lib/python3.8/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import xml.etree.ElementTree as xml\n",
    "import pandas as pd\n",
    "from nilearn.plotting import plot_surf_stat_map\n",
    "from matplotlib import pyplot as plt\n",
    "import ciftools_af as ct\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def extract_zone_convergence(sub, hemi, brain_structure):\n",
    "    # load surf\n",
    "    surf_raw = nib.load(f'{root_dir}{sub}/Structural/{sub}.{hemi}.midthickness_MSMAll.32k_fs_LR.surf.gii')\n",
    "    surf = []\n",
    "    surf.append(surf_raw.darrays[0].data)\n",
    "    surf.append(surf_raw.darrays[1].data)\n",
    "    vertices, triangles = surf#[surf_raw.darrays[i].data for i in range(2)]\n",
    "\n",
    "    # load labels\n",
    "    labels = nib.load(f'{root_dir}{sub}/Structural/{sub}.zone_prim.32k_fs_LR.dlabel.nii')\n",
    "    zones = labels.get_fdata().squeeze()\n",
    "\n",
    "    brain_model = [x for x in labels.header.get_index_map(1).brain_models if x.brain_structure==brain_structure][0]\n",
    "    offset = brain_model.index_offset\n",
    "    cortex = np.asarray(brain_model.vertex_indices[0:])\n",
    "    \n",
    "\n",
    "    z = np.zeros(vertices.shape[0])\n",
    "    z[cortex] = zones[offset:offset+len(cortex)]\n",
    "    # next step takes advantage of prod of 1,2,3 == 6.\n",
    "    coords = np.argwhere(np.prod(z[triangles], axis=1) == 6.)\n",
    "\n",
    "    # take more posterior node:\n",
    "    trig_of_interest = np.argmin([vertices[triangles[coords[0]]][0][:,1].mean(), vertices[triangles[coords[1]]][0][:,1].mean()])\n",
    "    nodes_of_interest = triangles[coords[trig_of_interest]][0]\n",
    "    \n",
    "    return nodes_of_interest\n",
    "\n",
    "\n",
    "### Find the scalar value associated to a set of vetices and a their percentile in a specified structure\n",
    "def get_scalar_pctile(cifti_scalar, vertices, brain_structure, scalar_row=0):\n",
    "    \n",
    "    # extract scalar values of all vertices, and the features of the brain structure from cifti\n",
    "    all_scalars = np.array(cifti_scalar.get_fdata()[scalar_row])\n",
    "    brain_model = [x for x in cifti_scalar.header.get_index_map(1).brain_models if x.brain_structure==brain_structure]\n",
    "    offset = brain_model[0].index_offset\n",
    "    count = brain_model[0].index_count\n",
    "    vertex_indices = np.array(brain_model[0].vertex_indices)\n",
    "    idx = np.array([i for i,x in enumerate(vertex_indices) if x in vertices])\n",
    "    \n",
    "    # get scalars and relative percentile\n",
    "    vertex_scalars = all_scalars[offset+idx]\n",
    "    scalar_pctiles = [stats.percentileofscore(all_scalars[offset:offset+count],scalar) for scalar in vertex_scalars]\n",
    "    del cifti_scalar\n",
    "    \n",
    "    return vertex_scalars, scalar_pctiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a4224c-579c-4d22-a12d-baf9f12dea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VARIABLES TO SET BEFORE RUNNING\n",
    "# directory containing subdirectories named fter subject IDs that contain the timeseries and surface files\n",
    "root_dir = \"/home/fralberti/Data/HCP/\"\n",
    "# directory where all intermediate files and the final output will be saved\n",
    "output_dir = \"/home/fralberti/Data/Output_misc/\"\n",
    "# list of IDs of subjects to include in the analyses\n",
    "f = open(f'{root_dir}subj_IDs_200.txt', 'r')\n",
    "subj_id = np.array(f.read().splitlines())\n",
    "del f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f287ed-08bb-4320-aad7-844ce029cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting principal gradient and percentile of convergence nodes, and performing permutation \n",
      "Current subject:\n",
      "\t100206\n",
      "\t100307\n",
      "\t100408\n",
      "\t101006\n",
      "\t101107\n",
      "\t101309\n",
      "\t101915\n",
      "\t102008\n",
      "\t102109\n",
      "\t102311\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Obtain the gradient values corresponding to the convergence nodes and relative percentile\n",
    "print(\"Extracting principal gradient and percentile of convergence nodes, and performing permutation \\nCurrent subject:\")\n",
    "\n",
    "# pre-assign the output dataframe\n",
    "gradientile_df = pd.DataFrame(columns=['ID_vtx','ID_grad','hemisphere',\n",
    "                                         'vertex1','vertex2','vertex3',\n",
    "                                         'mean','percentile'])\n",
    "for subj_grad in subj_id[0:10]:\n",
    "    print(f'\\t{subj_grad}')\n",
    "    # load a subject's gradient1\n",
    "    grads = nib.load(f'{root_dir}{subj_grad}/{subj_grad}.gcca_200.32k_fs_LR.dscalar.nii')\n",
    "    zones = nib.load(f'{root_dir}/HCP_S1200_GroupAvg_v1/zones.watershed.dlabel.nii').get_fdata()\n",
    "    # get gradient and percentile of convergence nodes of all subjs from the current grad       \n",
    "    mask_LR = []\n",
    "    \n",
    "    for hemi in ['L','R']:           \n",
    "        # extract hemisphere's gradient\n",
    "        brain_structure = ['CIFTI_STRUCTURE_CORTEX_LEFT' if hemi=='L' else 'CIFTI_STRUCTURE_CORTEX_RIGHT'][0]       \n",
    "        offset, count, vertex_indices = ct.struct_info(brain_structure, grads)\n",
    "        # apply lateral parietal mask\n",
    "        z = [2 if hemi=='L' else 3][0]\n",
    "        zone_hemi = zones[20, offset:offset+count]\n",
    "        mask = zone_hemi == z\n",
    "        mask_LR.extend(mask)\n",
    "        grad_zone = grads.get_fdata()[0, offset:offset+count][mask]\n",
    "\n",
    "        for subj_vtx in subj_id: \n",
    "            # extract principal gradient position of intersection vtx\n",
    "            vtx_of_interest = extract_zone_convergence(subj_vtx, hemi, brain_structure)\n",
    "            vtx_of_interest = np.sort(vtx_of_interest.tolist(),axis=0)\n",
    "            vtx_grad = np.median(grad_zone[np.isin(vertex_indices[mask],vtx_of_interest)])\n",
    "            vtx_pctile = stats.percentileofscore(grad_zone, vtx_grad)\n",
    "                        \n",
    "            # update output dataframe\n",
    "            gradientile_df = gradientile_df.append({'ID_vtx':subj_vtx,'ID_grad':subj_grad,'hemisphere':hemi,\n",
    "                                                    'vertex1':vtx_of_interest[0],'vertex2':vtx_of_interest[1],'vertex3':vtx_of_interest[2],\n",
    "                                                    'mean':vtx_grad,'percentile':vtx_pctile}, ignore_index=True)\n",
    "\n",
    "    ct.save_dscalar(np.array(mask_LR,ndmin=2), grads, f'{root_dir}{subj_grad}/Structural/{subj_grad}.zone_2.32k_fs_LR.dscalar.nii')\n",
    "\n",
    "\n",
    "del grads\n",
    "# save output        \n",
    "gradientile_df.to_csv(f'{output_dir}gradientiles_REST1_s6.csv',index=False)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4dbbd6-5c01-46e4-8b39-3fd480e0e1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LH:  WilcoxonResult(statistic=21.0, pvalue=0.556640625) \n",
      " RH:  WilcoxonResult(statistic=23.0, pvalue=0.6953125)\n"
     ]
    }
   ],
   "source": [
    "# Perform simple permutation test\n",
    "gradientile_df = pd.read_csv(f'{output_dir}gradientiles_REST1_s6.csv')\n",
    "X = gradientile_df[gradientile_df.ID_vtx==gradientile_df.ID_grad].set_index('ID_grad')\n",
    "Y = gradientile_df[gradientile_df.ID_vtx!=gradientile_df.ID_grad].groupby(['ID_grad','hemisphere']).agg('median').reset_index(level=1)\n",
    "L_wsrt = stats.wilcoxon(X.loc[X.hemisphere=='L','mean'],Y.loc[X.hemisphere=='L','mean'])\n",
    "R_wsrt = stats.wilcoxon(X.loc[X.hemisphere=='R','mean'],Y.loc[X.hemisphere=='R','mean'])\n",
    "print('LH: ', L_wsrt,'\\n','RH: ', R_wsrt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
